{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname=\"synthetic\"\n",
    "gpuid=0\n",
    "\n",
    "# --- densenet params\n",
    "#these parameters get fed directly into the densenet class, and more description of them can be discovered there\n",
    "n_classes= 2    #number of classes in the data mask that we'll aim to predict\n",
    "in_channels= 3  #input channel of the data, RGB = 3\n",
    "\n",
    "\n",
    "growth_rate=8 \n",
    "block_config=(6, 12, 24, 16)\n",
    "num_init_features=8\n",
    "bn_size=4\n",
    "drop_rate=0\n",
    "\n",
    "\n",
    "\n",
    "# --- training params\n",
    "batch_size=64\n",
    "patch_size=224 #currently, this needs to be 224 due to densenet architecture\n",
    "num_epochs = 100\n",
    "phases = [\"train\",\"val\"] #how many phases did we create databases for?\n",
    "validation_phases= [\"val\"] #when should we do valiation? note that validation is *very* time consuming, so as opposed to doing for both training and validation, we do it only for vlaidation at the end of the epoch\n",
    "                           #additionally, using simply [], will skip validation entirely, drastically speeding things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import tables\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import DenseNet\n",
    "\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for pretty printing of current time and remaining time\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent+.00001)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='Quadro M2200', major=5, minor=2, total_memory=4096MB, multi_processor_count=8)\n"
     ]
    }
   ],
   "source": [
    "#specify if we should use a GPU (cuda) or only the CPU\n",
    "print(torch.cuda.get_device_properties(gpuid))\n",
    "torch.cuda.set_device(gpuid)\n",
    "device = torch.device(f'cuda:{gpuid}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\torchvision\\models\\densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total params: \t444420\n"
     ]
    }
   ],
   "source": [
    "#build the model according to the paramters specified above and copy it to the GPU. finally print out the number of trainable parameters\n",
    " \n",
    "model = DenseNet(growth_rate=growth_rate, block_config=block_config,\n",
    "                 num_init_features=num_init_features, bn_size=bn_size, drop_rate=drop_rate, num_classes=n_classes).to(device)\n",
    "\n",
    "print(f\"total params: \\t{sum([np.prod(p.size()) for p in model.parameters()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this defines our dataset class which will be used by the dataloader\n",
    "class Dataset(object):\n",
    "    def __init__(self, fname ,img_transform=None):\n",
    "        #nothing special here, just internalizing the constructor parameters\n",
    "        self.fname=fname\n",
    "\n",
    "        self.img_transform=img_transform\n",
    "        \n",
    "        with tables.open_file(self.fname,'r') as db:\n",
    "            self.classsizes=db.root.classsizes[:]\n",
    "            self.nitems=db.root.imgs.shape[0]\n",
    "        \n",
    "        self.imgs = None\n",
    "        self.labels = None\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #opening should be done in __init__ but seems to be\n",
    "        #an issue with multithreading so doing here. need to do it everytime, otherwise hdf5 crashes\n",
    "\n",
    "        with tables.open_file(self.fname,'r') as db:\n",
    "            self.imgs=db.root.imgs\n",
    "            self.labels=db.root.labels\n",
    "\n",
    "            #get the requested image\n",
    "            img = self.imgs[index,::]\n",
    "            img = img[:,:,None].repeat(3,axis=2) #convert to 3 channel RGB\n",
    "            label = self.labels[index] \n",
    "        \n",
    "        img_new = img\n",
    "        \n",
    "        if self.img_transform is not None:\n",
    "            img_new = self.img_transform(img)\n",
    "\n",
    "        return img_new, label, img\n",
    "    def __len__(self):\n",
    "        return self.nitems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size:\t10000\n",
      "val dataset size:\t100\n"
     ]
    }
   ],
   "source": [
    "img_transform = transforms.Compose([\n",
    "     transforms.ToPILImage(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(size=(patch_size,patch_size),pad_if_needed=True), #these need to be in a reproducible order, first affine transforms and then color\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "dataset={}\n",
    "dataLoader={}\n",
    "for phase in phases: #now for each of the phases, we're creating the dataloader\n",
    "                     #interestingly, given the batch size, i've not seen any improvements from using a num_workers>0\n",
    "    \n",
    "    dataset[phase]=Dataset(f\"./{dataname}_{phase}.pytable\", img_transform=img_transform)\n",
    "    dataLoader[phase]=DataLoader(dataset[phase], batch_size=batch_size, \n",
    "                                shuffle=True, num_workers=8,pin_memory=True) \n",
    "    print(f\"{phase} dataset size:\\t{len(dataset[phase])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize a single example to verify that it is correct\n",
    "(img, label, img_old)=dataset[\"train\"][24]\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,4))  # 1 row, 2 columns\n",
    "\n",
    "#build output showing patch after augmentation and original patch\n",
    "ax[0].imshow(np.moveaxis(img.numpy(),0,-1))\n",
    "ax[1].imshow(img_old)\n",
    "\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters()) #adam is going to be the most robust, though perhaps not the best performing, typically a good place to start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have the ability to weight individual classes, in this case we'll do so based on their presense in the trainingset\n",
    "#to avoid biasing any particular class\n",
    "nclasses = dataset[\"train\"].classsizes.shape[0]\n",
    "class_weight=dataset[\"train\"].classsizes\n",
    "class_weight = torch.from_numpy(1-class_weight/class_weight.sum()).type('torch.FloatTensor').to(device)\n",
    "\n",
    "print(class_weight) #show final used weights, make sure that they're reasonable before continouing\n",
    "criterion = torch.nn.CrossEntropyLoss(weight = class_weight) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def trainnetwork():\n",
    "writer=SummaryWriter() #open the tensorboard visualiser\n",
    "best_loss_on_test = np.Infinity\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    #zero out epoch based performance variables \n",
    "    all_acc = {key: 0 for key in phases} \n",
    "    all_loss = {key: torch.zeros(0).to(device) for key in phases} #keep this on GPU for greatly improved performance\n",
    "    cmatrix = {key: np.zeros((n_classes,n_classes)) for key in phases}\n",
    "\n",
    "    for phase in phases: #iterate through both training and validation states\n",
    "\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else: #when in eval mode, we don't want parameters to be updated\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        for ii , (X, label, img_orig) in enumerate(dataLoader[phase]): #for each of the batches\n",
    "            X = X.to(device)  # [Nbatch, 3, H, W]\n",
    "            label = label.type('torch.LongTensor').to(device)  # [Nbatch, 1] with class indices (0, 1, 2,...n_classes)\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'): #dynamically set gradient computation, in case of validation, this isn't needed\n",
    "                                                            #disabling is good practice and improves inference time\n",
    "\n",
    "                prediction = model(X)  # [Nbatch, Nclass]\n",
    "                loss = criterion(prediction, label)\n",
    "\n",
    "\n",
    "                if phase==\"train\": #in case we're in train mode, need to do back propogation\n",
    "                    optim.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optim.step()\n",
    "                    train_loss = loss\n",
    "\n",
    "\n",
    "                all_loss[phase]=torch.cat((all_loss[phase],loss.detach().view(1,-1)))\n",
    "\n",
    "                if phase in validation_phases: #if this phase is part of validation, compute confusion matrix\n",
    "                    p=prediction.detach().cpu().numpy()\n",
    "                    cpredflat=np.argmax(p,axis=1).flatten()\n",
    "                    yflat=label.cpu().numpy().flatten()\n",
    "\n",
    "                    cmatrix[phase]=cmatrix[phase]+confusion_matrix(yflat,cpredflat, labels=range(nclasses))\n",
    "\n",
    "        all_acc[phase]=(cmatrix[phase]/cmatrix[phase].sum()).trace()\n",
    "        all_loss[phase] = all_loss[phase].cpu().numpy().mean()\n",
    "\n",
    "        #save metrics to tensorboard\n",
    "        writer.add_scalar(f'{phase}/loss', all_loss[phase], epoch)\n",
    "        if phase in validation_phases:\n",
    "            writer.add_scalar(f'{phase}/acc', all_acc[phase], epoch)\n",
    "            for r in range(nclasses):\n",
    "                for c in range(nclasses): #essentially write out confusion matrix\n",
    "                    writer.add_scalar(f'{phase}/{r}{c}', cmatrix[phase][r][c],epoch)\n",
    "\n",
    "    print('%s ([%d/%d] %d%%), train loss: %.4f test loss: %.4f' % (timeSince(start_time, (epoch+1) / num_epochs), \n",
    "                                                 epoch+1, num_epochs ,(epoch+1) / num_epochs * 100, all_loss[\"train\"], all_loss[\"val\"]),end=\"\")    \n",
    "\n",
    "    #if current loss is the best we've seen, save model state with all variables\n",
    "    #necessary for recreation\n",
    "    if all_loss[\"val\"] < best_loss_on_test:\n",
    "        best_loss_on_test = all_loss[\"val\"]\n",
    "        print(\"  **\")\n",
    "        state = {'epoch': epoch + 1,\n",
    "         'model_dict': model.state_dict(),\n",
    "         'optim_dict': optim.state_dict(),\n",
    "         'best_loss_on_test': all_loss,\n",
    "         'n_classes': n_classes,\n",
    "         'in_channels': in_channels,\n",
    "         'growth_rate':growth_rate,\n",
    "         'block_config':block_config,\n",
    "         'num_init_features':num_init_features,\n",
    "         'bn_size':bn_size,\n",
    "         'drop_rate':drop_rate}\n",
    "\n",
    "\n",
    "        torch.save(state, f\"{dataname}_densenet_best_model.pth\")\n",
    "    else:\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext line_profiler\n",
    "# %lprun -f trainnetwork trainnetwork()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
