{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"make_hdf5.ipynb","provenance":[{"file_id":"1SMDYDznKepcpxhrflAAVK7fNIkxBXlW3","timestamp":1591809200196}],"collapsed_sections":[],"authorship_tag":"ABX9TyMfAiiGoCccy3KGw33zq5z3"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"_6k7gKclKVWt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":138},"executionInfo":{"status":"ok","timestamp":1592569022997,"user_tz":240,"elapsed":20561,"user":{"displayName":"Tasneem Talawalla","photoUrl":"","userId":"02149208994079615985"}},"outputId":"1165f072-1574-41b0-ec45-87f93b48d8c6"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My\\ Drive/PytorchDigitalPathology/classification_lymphoma_densenet/data/"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n","/gdrive/My Drive/PytorchDigitalPathology/classification_lymphoma_densenet/data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ak50KC9yLa4T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592569027193,"user_tz":240,"elapsed":515,"user":{"displayName":"Tasneem Talawalla","photoUrl":"","userId":"02149208994079615985"}}},"source":["#v3.classification\n","#28/11/2018\n","\n","dataname=\"lymphoma\"\n","\n","patch_size=256 #size of the tiles to extract and save in the database, must be >= to training size\n","stride_size=256 #distance to skip between patches, 1 indicated pixel wise extraction, patch_size would result in non-overlapping tiles\n","mirror_pad_size=128 # number of pixels to pad *after* resize to image with by mirroring (edge's of patches tend not to be analyzed well, so padding allows them to appear more centered in the patch)\n","test_set_size=.1 # what percentage of the dataset should be used as a held out validation/testing set\n","resize=1 #resize input images\n","class_names=[\"CLL\", \"FL\", \"MCL\"]#what classes we expect to have in the data, here we have only 2 classes but we could add additional classes\n","\n","#-----Note---\n","#One should likely make sure that  (nrow+mirror_pad_size) mod patch_size == 0, where nrow is the number of rows after resizing\n","#so that no pixels are lost (any remainer is ignored)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"YwrFs146Ln3B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592569032803,"user_tz":240,"elapsed":3531,"user":{"displayName":"Tasneem Talawalla","photoUrl":"","userId":"02149208994079615985"}},"outputId":"f54d6a7c-a8cc-4404-ee0a-a849a7a1f5d5"},"source":["import torch\n","import tables\n","\n","import os,sys\n","import glob\n","\n","import PIL\n","import numpy as np\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","from sklearn import model_selection\n","import sklearn.feature_extraction.image\n","import random\n","\n","\n","seed = random.randrange(sys.maxsize) #get a random seed so that we can reproducibly do the cross validation setup\n","random.seed(seed) # set the seed\n","print(f\"random seed (note down for reproducibility): {seed}\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["random seed (note down for reproducibility): 7021975981264117584\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OayL3LZrL5Ar","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592569034058,"user_tz":240,"elapsed":546,"user":{"displayName":"Tasneem Talawalla","photoUrl":"","userId":"02149208994079615985"}}},"source":["img_dtype = tables.UInt8Atom()  # dtype in which the images will be saved, this indicates that images will be saved as unsigned int 8 bit, i.e., [0,255]\n","filenameAtom = tables.StringAtom(itemsize=255) #create an atom to store the filename of the image, just incase we need it later,"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"41KKjaEpL8P4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592569036397,"user_tz":240,"elapsed":526,"user":{"displayName":"Tasneem Talawalla","photoUrl":"","userId":"02149208994079615985"}}},"source":["files=glob.glob('**/*.tif') # create a list of the files, in this case we're only interested in files which have masks so we can use supervised learning\n","\n","#create training and validation stages and split the files appropriately between them\n","phases={}\n","phases[\"train\"],phases[\"val\"]=next(iter(model_selection.ShuffleSplit(n_splits=1,test_size=test_set_size).split(files)))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"mTlHayS4NZ4m","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592569037953,"user_tz":240,"elapsed":473,"user":{"displayName":"Tasneem Talawalla","photoUrl":"","userId":"02149208994079615985"}}},"source":["#--subset for rapid testing\n","phases[\"train\"]=phases[\"train\"][0:100]\n","phases[\"val\"]=phases[\"val\"][0:20]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"JaygcICbNs-i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"78d3c5ca-917e-4a65-c2fb-3b34facc5ede"},"source":["storage={} #holder for future pytables\n","\n","block_shape=np.array((patch_size,patch_size,3)) #block shape specifies what we'll be saving into the pytable array, here we assume that masks are 1d and images are 3d\n","\n","filters=tables.Filters(complevel=6, complib='zlib') #we can also specify filters, such as compression, to improve storage speed\n","\n","\n","for phase in phases.keys(): #now for each of the phases, we'll loop through the files\n","    print(phase)\n","    \n","    totals=np.zeros(len(class_names)) # we can to keep counts of all the classes in for in particular training, since we \n","    \n","    hdf5_file = tables.open_file(f\"./{dataname}_{phase}.pytable\", mode='w') #open the respective pytable\n","    storage[\"filenames\"] = hdf5_file.create_earray(hdf5_file.root, 'filenames', filenameAtom, (0,)) #create the array for storage\n","    \n","    storage[\"imgs\"]= hdf5_file.create_earray(hdf5_file.root, \"imgs\", img_dtype,  \n","                                              shape=np.append([0],block_shape), \n","                                              chunkshape=np.append([1],block_shape),\n","                                              filters=filters)\n","    storage[\"labels\"]= hdf5_file.create_earray(hdf5_file.root, \"labels\", img_dtype,  \n","                                              shape=[0], \n","                                              chunkshape=[1],\n","                                              filters=filters)\n","\n","    \n","    for filei in phases[phase]: #now for each of the files\n","        fname=files[filei] \n","        \n","        print(fname)\n","        classid=[idx for idx in range(len(class_names)) if class_names[idx] in fname][0]\n","        totals[classid]+=1\n","\n","        io=cv2.cvtColor(cv2.imread(fname),cv2.COLOR_BGR2RGB)\n","        interp_method=PIL.Image.BICUBIC\n","\n","\n","        io = cv2.resize(io,(0,0),fx=resize,fy=resize, interpolation=interp_method) #resize it as specified above\n","        io = np.pad(io, [(mirror_pad_size, mirror_pad_size), (mirror_pad_size, mirror_pad_size), (0, 0)], mode=\"reflect\")\n","\n","        #convert input image into overlapping tiles, size is ntiler x ntilec x 1 x patch_size x patch_size x3\n","        io_arr_out=sklearn.feature_extraction.image.extract_patches(io,(patch_size,patch_size,3),stride_size)\n","\n","        #resize it into a ntile x patch_size x patch_size x 3\n","        io_arr_out=io_arr_out.reshape(-1,patch_size,patch_size,3)\n","\n","\n","\n","        storage[\"imgs\"].append(io_arr_out)\n","        storage[\"labels\"].append([classid for x in range(io_arr_out.shape[0])]) #add the filename to the storage array\n","        storage[\"filenames\"].append([fname for x in range(io_arr_out.shape[0])]) #add the filename to the storage array\n","        \n","    #lastely, we should store the number of pixels\n","    npixels=hdf5_file.create_carray(hdf5_file.root, 'classsizes', tables.Atom.from_dtype(totals.dtype), totals.shape)\n","    npixels[:]=totals\n","    hdf5_file.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train\n","MCL/sj-04-3077-R2_003.tif\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function extract_patches is deprecated; The function feature_extraction.image.extract_patches has been deprecated in 0.22 and will be removed in 0.24.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["MCL/sj-04-4967-R2_004.tif\n","MCL/sj-05-5326-R1_012.tif\n","FL/sj-05-5389-R1_002.tif\n","FL/sj-05-5389-R1_003.tif\n","FL/sj-05-1881-R1_007.tif\n","CLL/sj-03-476_001.tif\n","MCL/sj-05-3362-R2_004.tif\n","FL/sj-05-4881-R3_003.tif\n","CLL/sj-05-3874-R2_010.tif\n","MCL/sj-05-4179-R1_002.tif\n","MCL/sj-04-4525-R4_010.tif\n","FL/sj-05-4881-R3_009.tif\n","FL/sj-05-1467-R1_003.tif\n","CLL/sj-05-1396-R3_008.tif\n","CLL/sj-03-852-R2_004.tif\n","MCL/sj-05-768_005.tif\n","MCL/sj-05-5326-R1_003.tif\n","FL/sj-05-6124-R4_010.tif\n","FL/sj-05-588-R1_003.tif\n","CLL/sj-05-5269-R10_004.tif\n","FL/sj-05-588-R1_001.tif\n","CLL/sj-03-5521_007.tif\n","FL/sj-05-5389-R1_013.tif\n","CLL/sj-05-3344_002.tif\n","CLL/sj-05-3165_005.tif\n","FL/sj-05-1467-R1_002.tif\n","CLL/sj-05-3165_003.tif\n","FL/sj-05-6124-R4_016.tif\n","FL/sj-05-4881-R3_010.tif\n","MCL/sj-04-4967-R2_005.tif\n","FL/sj-05-1881-R1_003.tif\n","MCL/sj-05-3362-R2_014.tif\n","FL/sj-05-894-R3_010.tif\n","MCL/sj-04-4967-R2_007.tif\n","CLL/sj-03-476_004.tif\n","MCL/sj-04-4967-R2_010.tif\n","CLL/sj-03-4957_004.tif\n","FL/sj-05-588-R1_006.tif\n","FL/sj-05-894-R3_005.tif\n","MCL/sj-05-768_011.tif\n","MCL/sj-04-6010-R3_011.tif\n","MCL/sj-05-768_004.tif\n","CLL/sj-05-3874-R2_001.tif\n","FL/sj-05-1881-R1_019.tif\n","FL/sj-05-1467-R1_006.tif\n","MCL/sj-05-1374_009.tif\n","FL/sj-05-6124-R4_014.tif\n","CLL/sj-05-3344_009.tif\n","MCL/sj-05-901-R1_006.tif\n","FL/sj-05-894-R3_008.tif\n","CLL/sj-05-5269-R10_013.tif\n","CLL/sj-05-3874-R2_006.tif\n","MCL/sj-04-4525-R4_008.tif\n","MCL/sj-05-901-R1_004.tif\n","MCL/sj-05-5326-R1_006.tif\n","FL/sj-05-6124-R3_013.tif\n","MCL/sj-05-4179-R1_010.tif\n","CLL/sj-03-5521_010.tif\n","FL/sj-05-588-R1_002.tif\n","CLL/sj-05-3344_005.tif\n","MCL/sj-04-4525-R4_009.tif\n","MCL/sj-05-3362-R2_001.tif\n","MCL/sj-05-4179-R1_005.tif\n","FL/sj-05-4881-R3_001.tif\n","FL/sj-05-6124-R4_006.tif\n","CLL/sj-03-476_010.tif\n","FL/sj-05-5389-R1_019.tif\n","MCL/sj-04-6010-R3_008.tif\n","MCL/sj-05-768_013.tif\n","FL/sj-05-6124-R3_002.tif\n","CLL/sj-05-1396-R3_006.tif\n","FL/sj-05-5311-R1_008.tif\n","FL/sj-05-4881-R3_007.tif\n","CLL/sj-05-1396-R3_004.tif\n","FL/sj-05-5389-R1_010.tif\n","FL/sj-05-5311-R1_003.tif\n","MCL/sj-05-4179-R1_004.tif\n","FL/sj-05-5829_002.tif\n","FL/sj-05-6124-R4_007.tif\n","CLL/sj-03-2810_007.tif\n","CLL/sj-03-5521_003.tif\n","CLL/sj-05-3874-R2_008.tif\n","FL/sj-05-1881-R1_010.tif\n","MCL/sj-05-1374_003.tif\n","FL/sj-05-588-R1_007.tif\n","MCL/sj-05-4179-R1_003.tif\n","FL/sj-05-5311-R1_006.tif\n","CLL/sj-03-852-R2_009.tif\n","FL/sj-05-5311-R1_011.tif\n","FL/sj-05-5311-R1_005.tif\n","MCL/sj-05-1374_005.tif\n","CLL/sj-05-3165_010.tif\n","MCL/sj-04-4525-R4_004.tif\n","CLL/sj-05-1396-R3_007.tif\n","FL/sj-05-1881-R1_001.tif\n","CLL/sj-05-3344_007.tif\n","FL/sj-05-5389-R1_017.tif\n","CLL/sj-03-476_002.tif\n","FL/sj-05-1881-R1_006.tif\n","val\n","FL/sj-05-1881-R1_008.tif\n","FL/sj-05-5829_003.tif\n","FL/sj-05-6124-R4_013.tif\n","CLL/sj-03-5521_002.tif\n","FL/sj-05-6124-R4_011.tif\n","MCL/sj-05-3362-R2_006.tif\n","MCL/sj-05-5326-R1_004.tif\n","CLL/sj-05-5269-R10_008.tif\n","FL/sj-05-6124-R3_005.tif\n","CLL/sj-03-5521_009.tif\n","CLL/sj-03-476_008.tif\n","CLL/sj-05-3874-R2_007.tif\n","MCL/sj-04-4525-R4_012.tif\n","FL/sj-05-6124-R3_006.tif\n","MCL/sj-04-4525-R4_001.tif\n","FL/sj-05-6124-R4_002.tif\n"],"name":"stdout"}]}]}